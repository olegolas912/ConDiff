{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D-qv6cnI16C",
        "outputId": "b0b45d4c-5666-403e-a5e7-f9eac13ecea7"
      },
      "outputs": [],
      "source": [
        "# # # !pip install -r requirements.txt\n",
        "# # !pip install --upgrade jax jaxlib\n",
        "# # !pip install --upgrade equinox # Add this line to upgrade equinox\n",
        "# # !pip install -U \"datasets>=2.19.0\"\n",
        "# !pip install --upgrade \"jax[cuda12]==0.6.0\" jax-cuda12-plugin==0.6.0\n",
        "# #           └─ installs jaxlib 0.6.0 automatically\n",
        "# !pip install equinox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoBF28TOegGf",
        "outputId": "073309aa-7544-43cf-857e-ad271299c78b"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# target_dir = \"/content/drive/MyDrive/ConDiff-main\"\n",
        "\n",
        "# os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# os.chdir(target_dir)\n",
        "\n",
        "# print(\"Текущая рабочая директория:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ks55JErFIjgj"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5Y4VMMRJFzP"
      },
      "outputs": [],
      "source": [
        "# import optax\n",
        "# import equinox as eqx\n",
        "import numpy as np\n",
        "# import jax.numpy as jnp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from IPython import display\n",
        "from functools import partial\n",
        "# from jax.lax import scan, dot_general\n",
        "from load_ConDiff import load_ConDiff\n",
        "# from architectures import UNet\n",
        "# from jax import config, random, grad, vmap, jit\n",
        "# from jax.tree_util import tree_map, tree_flatten\n",
        "import torch, time, pandas as pd\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from architectures.IAFNO_pt import get_IAFNO_pt\n",
        "import os\n",
        "import math\n",
        "from itertools import product\n",
        "from copy import deepcopy\n",
        "\n",
        "CHECKPOINT_PATH = \"iafno_poisson64.pth\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p6mpF87cnkhv"
      },
      "outputs": [],
      "source": [
        "def relative_error(pred, targ):\n",
        "    return ((pred - targ).view(pred.size(0), -1).norm(dim=1) /\n",
        "            targ.view(targ.size(0), -1).norm(dim=1))\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, history, path=CHECKPOINT_PATH):\n",
        "    torch.save({\n",
        "        \"epoch\":   epoch,\n",
        "        \"model\":   model.state_dict(),\n",
        "        \"optim\":   optimizer.state_dict(),\n",
        "        \"history\": history,\n",
        "    }, path)\n",
        "\n",
        "def load_checkpoint(model, optimizer=None, path=CHECKPOINT_PATH, map_location=\"cpu\"):\n",
        "    ckpt = torch.load(path, map_location=map_location)\n",
        "    model.load_state_dict(ckpt[\"model\"])\n",
        "    if optimizer is not None:\n",
        "        optimizer.load_state_dict(ckpt[\"optim\"])\n",
        "    return ckpt[\"epoch\"], ckpt[\"history\"]\n",
        "\n",
        "def huber_relative_error(pred, targ, delta=0.01):\n",
        "    \"\"\"\n",
        "    Huber-loss по пикселям, затем нормируем на ‖target‖, как в relative_error.\n",
        "    delta — порог между L1 и L2; 0.01 работает для карт в диапазоне ~[0,1].\n",
        "    \"\"\"\n",
        "    diff = pred - targ\n",
        "    abs_diff = diff.abs()\n",
        "    quad = torch.clamp(abs_diff, max=delta)\n",
        "    lin  = abs_diff - quad\n",
        "    huber = 0.5 * quad.pow(2) / delta + lin           # SmoothL1 вручную\n",
        "    per_sample = huber.view(huber.size(0), -1).sum(dim=1)\n",
        "    denom = targ.view(targ.size(0), -1).norm(dim=1) + 1e-8\n",
        "    return per_sample / denom\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zp887Oq1nm8D"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import math, torch\n",
        "\n",
        "def train_model_pt(model_data, features, targets, spec, device, use_huber=False):\n",
        "    \"\"\"обучает модель и возвращает (model, history_train, history_test)\"\"\"\n",
        "\n",
        "    model = model_data[\"model\"]\n",
        "    feats_tr, feats_ts = features\n",
        "    targs_tr, targs_ts = targets\n",
        "\n",
        "    # ---- оптимизатор -----------------------------------------------------\n",
        "    opt = torch.optim.AdamW(model.parameters(),\n",
        "                            lr=spec[\"learning_rate\"],\n",
        "                            weight_decay=spec[\"weight_decay\"])\n",
        "\n",
        "    # ---- scheduler: 5 % warm-up + косинусный спад ------------------------\n",
        "    steps_per_epoch = math.ceil(feats_tr.size(0) / spec[\"batch_size\"])\n",
        "    total_steps     = spec[\"N_epochs\"] * steps_per_epoch\n",
        "    scheduler = StepLR(opt, step_size=50, gamma=0.5)\n",
        "\n",
        "    # ---- выбор функции ошибки -------------------------------------------\n",
        "    loss_fn = huber_relative_error if use_huber else relative_error\n",
        "\n",
        "    best_test = float(\"inf\")\n",
        "    hist_train, hist_test = [], []\n",
        "\n",
        "    global_step = 0\n",
        "    epoch_bar = tqdm(range(1, spec[\"N_epochs\"] + 1), desc=\"Epochs\", position=0)\n",
        "\n",
        "    for epoch in epoch_bar:\n",
        "        model.train()\n",
        "        idx = torch.randperm(feats_tr.size(0), device=device)\n",
        "\n",
        "        # ----- батчи -----\n",
        "        batch_bar = tqdm(range(0, len(idx), spec[\"batch_size\"]),\n",
        "                         desc=f\"e{epoch}\", leave=False, position=1)\n",
        "\n",
        "        for i in batch_bar:\n",
        "            b = idx[i:i+spec[\"batch_size\"]]\n",
        "            pred = model(feats_tr[b])\n",
        "            loss = loss_fn(pred, targs_tr[b]).mean()\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            global_step += 1\n",
        "            batch_bar.set_postfix(train_loss=f\"{loss.item():.4e}\",\n",
        "                                  lr=scheduler.get_last_lr()[0])\n",
        "\n",
        "        # ----- валидация -----\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            pred_ts   = model(feats_ts)\n",
        "            test_loss = loss_fn(pred_ts, targs_ts).mean()\n",
        "\n",
        "        hist_train.append(loss.item())\n",
        "        hist_test.append(test_loss.item())\n",
        "        epoch_bar.set_postfix(train=f\"{loss.item():.4e}\",\n",
        "                              test=f\"{test_loss.item():.4e}\",\n",
        "                              lr=scheduler.get_last_lr()[0])\n",
        "        scheduler.step()\n",
        "\n",
        "        # чекпойнт, если улучшилось\n",
        "        if test_loss < best_test:\n",
        "            best_test = test_loss\n",
        "            save_checkpoint(model, opt, epoch,\n",
        "                            {\"train\": hist_train, \"test\": hist_test})\n",
        "\n",
        "    return model, hist_train, hist_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3Lae38gCnn4H"
      },
      "outputs": [],
      "source": [
        "def get_results(grid, type_of_pde=\"poisson\", direction_to_save=\"data\"):\n",
        "    import load_ConDiff\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # 1. датасет\n",
        "    (feat_tr, targ_tr), (feat_ts, targ_ts) = load_ConDiff.get_datasets(\n",
        "        direction_to_save, type_of_pde, grid\n",
        "    )\n",
        "    feat_tr = torch.tensor(feat_tr, dtype=torch.float32, device=device)\n",
        "    targ_tr = torch.tensor(targ_tr, dtype=torch.float32, device=device)\n",
        "    feat_ts = torch.tensor(feat_ts, dtype=torch.float32, device=device)\n",
        "    targ_ts = torch.tensor(targ_ts, dtype=torch.float32, device=device)\n",
        "\n",
        "    # 2. модель + оптимизация\n",
        "    model_data, spec = get_IAFNO(grid, device)\n",
        "    model, h_train, h_test = train_model_pt(\n",
        "        model_data,\n",
        "        [feat_tr, feat_ts],\n",
        "        [targ_tr, targ_ts],\n",
        "        spec,\n",
        "        device,\n",
        "        use_huber=True\n",
        "    )\n",
        "\n",
        "    # 3. итоговая метрика\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = model(feat_ts)\n",
        "        err  = relative_error(pred, targ_ts)\n",
        "    data = {\n",
        "        \"history_train\": h_train,\n",
        "        \"history_test\" : h_test,\n",
        "        \"test_error_mean\": err.mean().item(),\n",
        "        \"test_error_std\" : err.std().item()\n",
        "    }\n",
        "    return data, model, model_data, feat_ts, targ_ts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_results(model, history, features_test, targets_test):\n",
        "    \"\"\"\n",
        "    model         : обученная IAFNO (PyTorch)\n",
        "    history       : dict  {'history_train': [...], 'history_test': [...]}\n",
        "    features_test : torch.Tensor (N,1,H,W)  – rhs\n",
        "    targets_test  : torch.Tensor (N,1,H,W)  – solution\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = model(features_test).cpu().numpy()[:, 0]   # (N,H,W)\n",
        "\n",
        "    targ = targets_test.cpu().numpy()[:, 0]\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    plt.rcParams[\"font.family\"] = \"serif\"\n",
        "\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "    # кривая потерь\n",
        "    ax[0].set_title(\"Loss\")\n",
        "    ax[0].set_yscale(\"log\")\n",
        "    ax[0].plot(history[\"history_train\"], \"-\",  color=\"red\",   label=\"train\")\n",
        "    ax[0].plot(history[\"history_test\"],  \"-.\", color=\"green\", label=\"test\")\n",
        "    ax[0].legend();  ax[0].grid(ls=\"-.\")\n",
        "    ax[0].spines[[\"top\", \"right\"]].set_visible(False)\n",
        "\n",
        "    ax[1].contourf(pred[0]);  ax[1].set_title(\"Prediction\")\n",
        "    ax[2].contourf(targ[0]);  ax[2].set_title(\"Target\")\n",
        "\n",
        "    plt.tight_layout();  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqV68T0Onoyv",
        "outputId": "fd9f88ef-2af9-453b-bb44-75754e4e5965"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6398bf503fe54ecda996ce7efa8deee3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epochs:   0%|          | 0/400 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ad96d5f3b8247a28df8f2425d219e09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "e1:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d0883633de043d5827564c0b6b8792f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "e2:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЧекпойнт найден — обучение пропущено.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     model, h_tr, h_ts \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_pt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeat_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_ts\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarg_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarg_ts\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     history \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory_train\u001b[39m\u001b[38;5;124m\"\u001b[39m: h_tr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory_test\u001b[39m\u001b[38;5;124m\"\u001b[39m: h_ts}\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mОбучение завершено.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mtrain_model_pt\u001b[1;34m(model_data, features, targets, spec, device, use_huber)\u001b[0m\n\u001b[0;32m     53\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()          \u001b[38;5;66;03m# <-- обновляем LR\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 55\u001b[0m     batch_bar\u001b[38;5;241m.\u001b[39mset_postfix(train_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     56\u001b[0m                           lr\u001b[38;5;241m=\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mget_last_lr()[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# ----- валидация -----\u001b[39;00m\n\u001b[0;32m     59\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "grid   = 64\n",
        "CHECKPOINT_PATH = \"iafno_poisson64.pth\"\n",
        "\n",
        "model_data, spec = get_IAFNO_pt(grid, device)\n",
        "model = model_data[\"model\"]\n",
        "\n",
        "# ---------- датасет -------------------------------------------------------\n",
        "(rhs_tr, x_tr), (rhs_ts, x_ts) = load_ConDiff(\"data\", \"poisson\", grid)\n",
        "\n",
        "rhs_tr = rhs_tr.reshape(-1, 1, grid, grid)\n",
        "x_tr   = x_tr.reshape(-1, 1, grid, grid)\n",
        "rhs_ts = rhs_ts.reshape(-1, 1, grid, grid)\n",
        "x_ts   = x_ts.reshape(-1, 1, grid, grid)\n",
        "\n",
        "feat_tr = torch.tensor(rhs_tr, dtype=torch.float32, device=device)\n",
        "targ_tr = torch.tensor(x_tr,   dtype=torch.float32, device=device)\n",
        "feat_ts = torch.tensor(rhs_ts, dtype=torch.float32, device=device)\n",
        "targ_ts = torch.tensor(x_ts,   dtype=torch.float32, device=device)\n",
        "\n",
        "# 1) Добавляем двумерные координаты (x,y) в каналы:\n",
        "xs = torch.linspace(0, 1, grid, device=device)\n",
        "ys = torch.linspace(0, 1, grid, device=device)\n",
        "X, Y = torch.meshgrid(xs, ys, indexing=\"xy\")\n",
        "# coords.shape = (2, grid, grid) → (B,2,grid,grid)\n",
        "coords = torch.stack([X, Y], dim=0) \\\n",
        "            .unsqueeze(0) \\\n",
        "            .repeat(feat_tr.size(0), 1, 1, 1)\n",
        "feat_tr = torch.cat([feat_tr, coords], dim=1)  # (B,3,grid,grid)\n",
        "feat_ts = torch.cat(\n",
        "    [feat_ts, coords[: feat_ts.size(0)]], dim=1\n",
        ")\n",
        "\n",
        "# 2) Z-score нормировка forcing и target:\n",
        "f_mean, f_std = feat_tr.mean(), feat_tr.std()\n",
        "feat_tr = (feat_tr - f_mean) / f_std\n",
        "feat_ts = (feat_ts - f_mean) / f_std\n",
        "\n",
        "u_mean, u_std = targ_tr.mean(), targ_tr.std()\n",
        "targ_tr = (targ_tr - u_mean) / u_std\n",
        "targ_ts = (targ_ts - u_mean) / u_std\n",
        "\n",
        "\n",
        "# ---------- обучение или загрузка ----------------------------------------\n",
        "if os.path.isfile(CHECKPOINT_PATH):\n",
        "    _, hist = load_checkpoint(model, path=CHECKPOINT_PATH, map_location=device)\n",
        "    history = hist\n",
        "    print(\"Чекпойнт найден — обучение пропущено.\")\n",
        "else:\n",
        "    model, h_tr, h_ts = train_model_pt(\n",
        "        model_data,\n",
        "        [feat_tr, feat_ts],\n",
        "        [targ_tr, targ_ts],\n",
        "        spec,\n",
        "        device\n",
        "    )\n",
        "    history = {\"history_train\": h_tr, \"history_test\": h_ts}\n",
        "    print(\"Обучение завершено.\")\n",
        "\n",
        "# ---------- оценка и график ----------------------------------------------\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred = model(feat_ts)\n",
        "    err  = relative_error(pred, targ_ts)\n",
        "\n",
        "print(f\"IAFNO  test error: {err.mean():.3f} ± {err.std():.3f}\")\n",
        "\n",
        "plot_results(model, history, feat_ts, targ_ts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IAFNO  test error: 1.283 ± 0.306\n"
          ]
        }
      ],
      "source": [
        "print(f\"IAFNO  test error: {err.mean():.3f} ± {err.std():.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "search_space = {\n",
        "    \"width\" : [64, 96],\n",
        "    \"depth\" : [8, 10],\n",
        "    \"modes\" : [grid // 4],\n",
        "    \"n_imp\" : [2, 3],\n",
        "    \"lr\"    : [3e-4, 1e-4, 1e-5],\n",
        "    \"wd\"    : [1e-6],\n",
        "    \"batch\" : [16]\n",
        "}\n",
        "configs = [dict(zip(search_space, v)) for v in product(*search_space.values())]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "grid   = 64\n",
        "(rhs_tr, x_tr), (rhs_ts, x_ts) = load_ConDiff(\"data\",\"poisson\",grid)\n",
        "\n",
        "tr = torch.tensor(rhs_tr.reshape(-1,1,grid,grid), dtype=torch.float32, device=device)\n",
        "yr = torch.tensor(x_tr.reshape (-1,1,grid,grid), dtype=torch.float32, device=device)\n",
        "ts = torch.tensor(rhs_ts.reshape(-1,1,grid,grid), dtype=torch.float32, device=device)\n",
        "ys = torch.tensor(x_ts.reshape (-1,1,grid,grid), dtype=torch.float32, device=device)\n",
        "\n",
        "results = []\n",
        "\n",
        "for cfg_id, hp in enumerate(configs, 1):\n",
        "    print(f\"\\n>>> run {cfg_id}/{len(configs)}  {hp}\")\n",
        "\n",
        "    model_data, spec = get_IAFNO_pt(grid, device, **hp)\n",
        "    t0 = time.time()\n",
        "    model, h_tr, h_ts = train_model_pt(\n",
        "        model_data,\n",
        "        [tr, ts],\n",
        "        [yr, ys],\n",
        "        spec,\n",
        "        device,\n",
        "        use_huber=True\n",
        "    )\n",
        "    dt = time.time() - t0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        err = relative_error(model(ts), ys)\n",
        "    mean_err = err.mean().item()\n",
        "    std_err  = err.std().item()\n",
        "\n",
        "    row = deepcopy(hp)\n",
        "    row.update({\"mean\": mean_err, \"std\": std_err, \"time(min)\": dt/60})\n",
        "    results.append(row)\n",
        "\n",
        "    print(f\"err={mean_err:.3f} ± {std_err:.3f}  |  time {dt/60:.1f} min\")\n",
        "\n",
        "# -- сводная таблица и лучшая конфигурация --\n",
        "df = pd.DataFrame(results).sort_values(\"mean\")\n",
        "display(df.head())\n",
        "best = df.iloc[0].to_dict()\n",
        "print(\"\\nBEST:\", best)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
